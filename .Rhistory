library(shiny); runApp('shiny.R')
install.packages("ggplot2")
install.packages("ggplot2")
runApp('shiny.R')
runApp('~/Desktop/fina415/shiny.R')
library(shiny); runApp('shiny.R')
runApp('~/Desktop/fina415/shiny.R')
library(shiny); runApp('shiny.R')
getwd()
library(shiny); runApp('shiny copy.R')
getwd()
library(streamR)
library(twitteR)
install.packages("qdap")
install.packages("qdap")
library(qdap)
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
load("my_oauth.Rdata")
tweets1.df <- parseTweets("tweetUS.json",verbose=FALSE)
load("my_oauth.Rdata")
tweets1<- searchTwitter("Trump OR  #Trump", n=7000,  geocode="37.77493,-122.4194,50mi")
library(devtools)
library(twitteR)
api_key <- 	"bDp95I7S9arvEqPb8SccZ20Nn"
api_secret <- "piocWoAvWB4bcNbOW9VIaF0YyT2TUpi6TOakHg3voV4iiXXlQM"
access_token <- "793892699619426304-j8D2ivAINuq7fk7O2m9pg1RE7OQCHnP"
access_token_secret <- "Aa4fUH303hHdtxdWwhHpCabs9G6jwBcZTr8Jya4ubwL0c"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
tweets1<- searchTwitter("Trump OR  #Trump", n=7000,  geocode="37.77493,-122.4194,50mi")
df1 <- twListToDF(tweets1)
require(devtools)
install_url("http://cran.r-project.org/src/contrib/Archive/Rstem/Rstem_0.4-1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
install.packages("sentiment")
require(sentiment)
require(sentiment)
txt1 = sapply(tweets1, function(x) x$getText())
txt1 = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", txt1)
txt1 = gsub("@\\w+", "", txt1)
txt1 = gsub("[[:punct:]]", "", txt1)
txt1 = gsub("[[:digit:]]", "", txt1)
txt1 = gsub("http\\w+", "", txt1)
txt1 = gsub("[ \t]{2,}", "", txt1)
txt1 = gsub("^\\s+|\\s+$", "", txt1)
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
txt1 = sapply(txt1, try.error)
txt1 = txt1[!is.na(txt1)]
names(txt1) = NULL
txt1 <- gsub(" (the|to|is|its|on|and|of|in|for|a|after|from|but|that|about|was|you|it|i|with|if|so|can|this|where) "," ",txt1)
require(tm)
require(wordcloud)
require(wordcloud)
require(RColorBrewer)
ap.corpus <- Corpus(DataframeSource((data.frame(as.character(txt1)))))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=200, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=300, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=100, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
txt1 = sapply(tweets1, function(x) x$getText())
txt1 = sapply(tweets1, function(x) x$getText())
txt1 = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", txt1)
txt1 = gsub("@\\w+", "", txt1)
txt1 = gsub("[[:punct:]]", "", txt1)
txt1 = gsub("[[:digit:]]", "", txt1)
txt1 = gsub("http\\w+", "", txt1)
txt1 = gsub("[ \t]{2,}", "", txt1)
txt1 = gsub("^\\s+|\\s+$", "", txt1)
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
txt1 = sapply(txt1, try.error)
txt1 = txt1[!is.na(txt1)]
names(txt1) = NULL
txt1 <- gsub(" (the|to|is|its|on|and|of|in|for|a|after|from|but|that|about|was|you|it|i|with|if|so|can|this|where) "," ",txt1)
ap.corpus <- Corpus(DataframeSource((data.frame(as.character(txt1)))))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=100, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
tweets5<- searchTwitter("Trump OR  #Trump", n=7000,  geocode="41.87811,-87.6298,20mi")
df5 <- twListToDF(tweets5)
hour <-count(df5$created)
txt5 = sapply(tweets5, function(x) x$getText())
txt5 = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", txt5)
txt5 = gsub("@\\w+", "", txt5)
txt5 = gsub("[[:punct:]]", "", txt5)
txt5 = gsub("[[:digit:]]", "", txt5)
txt5 = gsub("http\\w+", "", txt5)
txt5 = gsub("[ \t]{2,}", "", txt5)
txt5 = gsub("^\\s+|\\s+$", "", txt5)
txt5 = sapply(txt5, try.error)
txt5 = txt5[!is.na(txt5)]
names(txt5) = NULL
txt5 <- gsub(" (the|to|is|its|on|and|of|in|for|a|after|from|but|that|about|was|you|it|i|with|if|so|can|this|where) "," ",txt1)
ap.corpus <- Corpus(DataframeSource((data.frame(as.character(txt5)))))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=100, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
tweets3<- searchTwitter("Trump OR  #Trump", n=7000,  geocode="42.36008,-71.05888,20mi")
df3 <- twListToDF(tweets3)
txt3 = sapply(tweets3, function(x) x$getText())
txt3 = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", txt3)
txt3 = gsub("@\\w+", "", txt3)
txt3 = gsub("[[:punct:]]", "", txt3)
txt3 = gsub("[[:digit:]]", "", txt3)
txt3 = gsub("http\\w+", "", txt3)
txt3 = gsub("[ \t]{2,}", "", txt3)
txt3 = gsub("^\\s+|\\s+$", "", txt3)
txt3 = sapply(txt3, try.error)
txt3 = txt3[!is.na(txt3)]
names(txt3) = NULL
txt3 <- gsub(" (the|to|is|its|on|and|of|in|for|a|after|from|but|that|about|was|you|it|i|with|if|so|can|this|where) "," ",txt1)
ap.corpus <- Corpus(DataframeSource((data.frame(as.character(txt3)))))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=300, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
tweets3<- searchTwitter("Trump OR  #Trump", n=7000,  geocode="42.36008,-71.05888,20mi")
df3 <- twListToDF(tweets3)
hour <-count(df3$created)
df3$hour <- hour
txt3 = sapply(tweets3, function(x) x$getText())
txt3 = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", txt3)
txt3 = gsub("@\\w+", "", txt3)
txt3 = gsub("[[:punct:]]", "", txt3)
txt3 = gsub("[[:digit:]]", "", txt3)
txt3 = gsub("http\\w+", "", txt3)
txt3 = gsub("[ \t]{2,}", "", txt3)
txt3 = gsub("^\\s+|\\s+$", "", txt3)
txt3 = sapply(txt3, try.error)
txt3 = txt3[!is.na(txt3)]
names(txt3) = NULL
ap.corpus <- Corpus(DataframeSource((data.frame(as.character(txt3)))))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=200, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=100, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
txt3 <- gsub(" (the|to|is|its|on|and|of|in|for|a|after|from|but|that|about|was|you|it|i|with|if|so|can|this|where) "," ",txt1)
txt3 <- gsub(" (the|to|is|its|on|and|of|in|for|a|after|from|but|that|about|was|you|it|i|with|if|so|can|this|where) "," ",txt1)
ap.corpus <- Corpus(DataframeSource((data.frame(as.character(txt3)))))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,max.words=100, random.order=FALSE, rot.per=.15, colors=brewer.pal(8,"Dark2"))
library(shiny); runApp('shiny1.R')
runApp('shiny1.R')
runApp('shiny1.R')
library(shiny); runApp('shiny1.R')
getwd()
